{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6f470c8-a4d9-4b2d-9179-e01f4e6b7ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c692c25-567e-45e9-8795-c06f01ca70fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductSearchDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.data = dataset\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "        \n",
    "    # def __getitem__(self, index):\n",
    "    #     # Get product ID and its description\n",
    "    #     product_id = self.data.loc[index, 'id']\n",
    "    #     product_desc = self.data.loc[index, 'description']\n",
    "    #     product_cluster = self.data.loc[index, 'label']\n",
    "        \n",
    "    #     # Get all queries for this product\n",
    "    #     product_queries = self.data.loc[index, ['query_1', 'query_2', 'query_3', 'query_4', 'query_5']]\n",
    "        \n",
    "    #     # Randomly select one query for training\n",
    "    #     query = np.random.choice(product_queries)\n",
    "        \n",
    "    #     return query, product_desc, product_id, cluster_id\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "\n",
    "        # Extract data\n",
    "        product_id = row['id']\n",
    "        product_desc = row['description']\n",
    "        product_cluster = row['label']\n",
    "        \n",
    "        # Get all queries\n",
    "        product_queries = row[['query_1', 'query_2', 'query_3', 'query_4', 'query_5']].values\n",
    "    \n",
    "        # Randomly select one query\n",
    "        query = np.random.choice(product_queries)\n",
    "    \n",
    "        return query, product_desc, product_id, product_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d2f527c-2234-417a-9e63-9e992dd73fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/home_products_with_sample_queries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bb6c094-fc04-40f4-aa29-3107bbb66996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>label</th>\n",
       "      <th>query_1</th>\n",
       "      <th>query_2</th>\n",
       "      <th>query_3</th>\n",
       "      <th>query_4</th>\n",
       "      <th>query_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0BFJL5LD1</td>\n",
       "      <td>VGYVGYCC Outdoor Solar Garden Lights - 2 Pack ...</td>\n",
       "      <td>2022 Newest Version2 pack solar tulip lights a...</td>\n",
       "      <td>12</td>\n",
       "      <td>Large decorative solar lights</td>\n",
       "      <td>Easy to install garden lights</td>\n",
       "      <td>Waterproof outdoor tulip lights</td>\n",
       "      <td>Gift idea for garden decor</td>\n",
       "      <td>High-quality solar tulip lights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B0002H49E4</td>\n",
       "      <td>LEATHERMAN - Standard Nylon Sheath with Pocket...</td>\n",
       "      <td>Product Description This nylon belt sheath is ...</td>\n",
       "      <td>55</td>\n",
       "      <td>Sturdy nylon belt sheath</td>\n",
       "      <td>Sheath for Leatherman Wave</td>\n",
       "      <td>Multitool sheath with pockets</td>\n",
       "      <td>Durable vertical carry sheath</td>\n",
       "      <td>Leatherman Wave belt sheath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B084GYHQFY</td>\n",
       "      <td>Makita MAC210Q Quiet Series, 1 HP, 2 Gallon, O...</td>\n",
       "      <td>Compressors are workhorse tools on the job sit...</td>\n",
       "      <td>31</td>\n",
       "      <td>Makita quiet air compressor</td>\n",
       "      <td>Portable electric air compressor</td>\n",
       "      <td>Lightweight 2-gallon compressor</td>\n",
       "      <td>Oil-free electric compressor</td>\n",
       "      <td>Low-noise air compressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B09ZP7M7R1</td>\n",
       "      <td>Greenclick Landscape Lighting, 3W 12V Extendab...</td>\n",
       "      <td>Safe Low Voltage Landscape LightsLow voltage l...</td>\n",
       "      <td>35</td>\n",
       "      <td>Safe low voltage landscape lights</td>\n",
       "      <td>Extendable garden spotlights</td>\n",
       "      <td>Bright outdoor Christmas lights</td>\n",
       "      <td>Waterproof garden spotlights</td>\n",
       "      <td>Landscape lighting set with transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0BRGRNK2H</td>\n",
       "      <td>20 oz Big Gap Filler Insulating Foam Sealant (...</td>\n",
       "      <td>Product Description GREAT STUFF Big Gap Filler...</td>\n",
       "      <td>8</td>\n",
       "      <td>Big gap filler foam sealant</td>\n",
       "      <td>Insulating foam for large gaps</td>\n",
       "      <td>Airtight sealant for drafts</td>\n",
       "      <td>Paintable foam insulation</td>\n",
       "      <td>Weather-tight foam sealant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                              title  \\\n",
       "0  B0BFJL5LD1  VGYVGYCC Outdoor Solar Garden Lights - 2 Pack ...   \n",
       "1  B0002H49E4  LEATHERMAN - Standard Nylon Sheath with Pocket...   \n",
       "2  B084GYHQFY  Makita MAC210Q Quiet Series, 1 HP, 2 Gallon, O...   \n",
       "3  B09ZP7M7R1  Greenclick Landscape Lighting, 3W 12V Extendab...   \n",
       "4  B0BRGRNK2H  20 oz Big Gap Filler Insulating Foam Sealant (...   \n",
       "\n",
       "                                         description  label  \\\n",
       "0  2022 Newest Version2 pack solar tulip lights a...     12   \n",
       "1  Product Description This nylon belt sheath is ...     55   \n",
       "2  Compressors are workhorse tools on the job sit...     31   \n",
       "3  Safe Low Voltage Landscape LightsLow voltage l...     35   \n",
       "4  Product Description GREAT STUFF Big Gap Filler...      8   \n",
       "\n",
       "                             query_1                           query_2  \\\n",
       "0      Large decorative solar lights     Easy to install garden lights   \n",
       "1           Sturdy nylon belt sheath        Sheath for Leatherman Wave   \n",
       "2        Makita quiet air compressor  Portable electric air compressor   \n",
       "3  Safe low voltage landscape lights      Extendable garden spotlights   \n",
       "4        Big gap filler foam sealant    Insulating foam for large gaps   \n",
       "\n",
       "                           query_3                        query_4  \\\n",
       "0  Waterproof outdoor tulip lights     Gift idea for garden decor   \n",
       "1    Multitool sheath with pockets  Durable vertical carry sheath   \n",
       "2  Lightweight 2-gallon compressor   Oil-free electric compressor   \n",
       "3  Bright outdoor Christmas lights   Waterproof garden spotlights   \n",
       "4      Airtight sealant for drafts      Paintable foam insulation   \n",
       "\n",
       "                                   query_5  \n",
       "0          High-quality solar tulip lights  \n",
       "1              Leatherman Wave belt sheath  \n",
       "2                 Low-noise air compressor  \n",
       "3  Landscape lighting set with transformer  \n",
       "4               Weather-tight foam sealant  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71011b56-0bf7-4e28-b453-186f6a663c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to create a train and validation dataset with sample sizes that are compatible with your batch size\n",
    "# train_dataset = df.sample(n=224)\n",
    "# val_dataset = df[~df.index.isin(train_dataset.index)].sample(64)\n",
    "train_dataset, val_dataset = train_test_split(df, test_size=0.2, random_state=3478)\n",
    "train_dataset.reset_index(drop=True, inplace=True)\n",
    "val_dataset.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5f18e8c-f120-4caa-b583-b93f729672c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryEncoder(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, output_embed_dim):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = torch.nn.Embedding(vocab_size, embed_dim)\n",
    "        # Use fewer transformer layers for queries since they're shorter\n",
    "        self.encoder = torch.nn.TransformerEncoder(\n",
    "            torch.nn.TransformerEncoderLayer(embed_dim, nhead=8, batch_first=True),\n",
    "            num_layers=2,\n",
    "            norm=torch.nn.LayerNorm([embed_dim]),\n",
    "            enable_nested_tensor=False\n",
    "        )\n",
    "        self.projection = torch.nn.Linear(embed_dim, output_embed_dim)\n",
    "        \n",
    "    def forward(self, tokenizer_output):\n",
    "        # Move inputs to the same device as the model\n",
    "        input_ids = tokenizer_output['input_ids'].to(self.embedding_layer.weight.device)\n",
    "        attention_mask = tokenizer_output['attention_mask'].to(self.embedding_layer.weight.device)\n",
    "        \n",
    "        x = self.embedding_layer(input_ids)\n",
    "        x = self.encoder(x, src_key_padding_mask=attention_mask.logical_not())\n",
    "        # Use mean pooling instead of CLS token for queries\n",
    "        # This helps capture information from all tokens in short queries\n",
    "        mask_expanded = attention_mask.unsqueeze(-1).expand(x.size())\n",
    "        sum_embeddings = torch.sum(x * mask_expanded, 1)\n",
    "        sum_mask = torch.sum(mask_expanded, 1)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return self.projection(mean_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c2dc873-a810-4bc2-bca3-aa8ccccdbbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductEncoder(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, output_embed_dim):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = torch.nn.Embedding(vocab_size, embed_dim)\n",
    "        # Use more transformer layers for product descriptions since they're longer\n",
    "        self.encoder = torch.nn.TransformerEncoder(\n",
    "            torch.nn.TransformerEncoderLayer(embed_dim, nhead=8, batch_first=True),\n",
    "            num_layers=4,\n",
    "            norm=torch.nn.LayerNorm([embed_dim]),\n",
    "            enable_nested_tensor=False\n",
    "        )\n",
    "        self.projection = torch.nn.Linear(embed_dim, output_embed_dim)\n",
    "        \n",
    "    def forward(self, tokenizer_output):\n",
    "        # Move inputs to the same device as the model\n",
    "        input_ids = tokenizer_output['input_ids'].to(self.embedding_layer.weight.device)\n",
    "        attention_mask = tokenizer_output['attention_mask'].to(self.embedding_layer.weight.device)\n",
    "        \n",
    "        x = self.embedding_layer(input_ids)\n",
    "        x = self.encoder(x, src_key_padding_mask=attention_mask.logical_not())\n",
    "        # Use CLS token for product descriptions\n",
    "        cls_embed = x[:,0,:]\n",
    "        return self.projection(cls_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "701efe34-c894-4201-add2-47cdb8295dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_hard_negative_sampling(product_ids, cluster_ids, product_embeddings, num_negatives=1):\n",
    "    \"\"\"\n",
    "    Sample hard negatives from the current batch, ensuring negatives come from different clusters.\n",
    "\n",
    "    Args:\n",
    "        product_ids (list): List of product IDs in the batch.\n",
    "        cluster_ids (list): List of corresponding cluster IDs in the batch.\n",
    "        product_embeddings (torch.Tensor): Tensor of product embeddings in the batch [batch_size, embed_dim].\n",
    "        num_negatives (int): Number of negatives per query.\n",
    "\n",
    "    Returns:\n",
    "        neg_embeddings (torch.Tensor): Tensor of hard negative product embeddings [batch_size, num_negatives, embed_dim].\n",
    "    \"\"\"\n",
    "    batch_size = len(product_ids)\n",
    "    neg_samples = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        # Get current cluster ID\n",
    "        current_cluster = cluster_ids[i]\n",
    "\n",
    "        # Find indices of products in the batch from a different cluster\n",
    "        negative_indices = [j for j in range(batch_size) if cluster_ids[j] != current_cluster]\n",
    "\n",
    "        # Sample negatives\n",
    "        sampled_negatives = random.sample(negative_indices, num_negatives)\n",
    "        \n",
    "        # Store their embeddings\n",
    "        neg_samples.append(product_embeddings[sampled_negatives])\n",
    "\n",
    "    # Stack negatives into a tensor [batch_size, num_negatives, embed_dim]\n",
    "    neg_embeddings = torch.stack(neg_samples).to(product_embeddings.device)\n",
    "    \n",
    "    return neg_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a9e2be2-57da-433d-b502-822c132d6d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(query_encoder, product_encoder, eval_dataset, tokenizer, query_max_len, product_max_len, k=10, device='cuda'):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the evaluation dataset\n",
    "    \n",
    "    Args:\n",
    "        query_encoder: Query encoder model\n",
    "        product_encoder: Product encoder model\n",
    "        eval_dataset: Evaluation dataset\n",
    "        tokenizer: Tokenizer\n",
    "        query_max_len: Maximum query length\n",
    "        product_max_len: Maximum product description length\n",
    "        k: Number of top results to consider for metrics\n",
    "        device: Device to use for computations\n",
    "    \"\"\"\n",
    "    query_encoder.eval()\n",
    "    product_encoder.eval()\n",
    "    \n",
    "    # Create evaluation dataloader\n",
    "    eval_dataloader = torch.utils.data.DataLoader(eval_dataset, batch_size=8, shuffle=False)\n",
    "    \n",
    "    # First pass: encode all products\n",
    "    all_product_ids = []\n",
    "    all_product_embeddings = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_data in tqdm(eval_dataloader, desc=\"Encoding Products\"):\n",
    "            _, product_descs, product_ids, _ = batch_data\n",
    "            \n",
    "            product_tokens = tokenizer(\n",
    "                product_descs, \n",
    "                padding=True, \n",
    "                truncation=True, \n",
    "                return_tensors=\"pt\", \n",
    "                max_length=product_max_len\n",
    "            )\n",
    "            \n",
    "            product_embeddings = product_encoder(product_tokens)\n",
    "            product_embeddings = torch.nn.functional.normalize(product_embeddings, p=2, dim=1)\n",
    "            \n",
    "            all_product_ids.extend(product_ids)\n",
    "            all_product_embeddings.append(product_embeddings.cpu())  # Move to CPU to save GPU memory\n",
    "    \n",
    "    # Concatenate all product embeddings\n",
    "    all_product_embeddings = torch.cat(all_product_embeddings, dim=0)\n",
    "    \n",
    "    # Second pass: evaluate queries\n",
    "    total_queries = 0\n",
    "    hits_at_k = 0\n",
    "    mrr = 0.0  # Mean Reciprocal Rank\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_data in tqdm(eval_dataloader, desc=\"Evaluating Queries\"):\n",
    "            queries, _, product_ids, _ = batch_data\n",
    "            \n",
    "            query_tokens = tokenizer(\n",
    "                queries, \n",
    "                padding=True, \n",
    "                truncation=True, \n",
    "                return_tensors=\"pt\", \n",
    "                max_length=query_max_len\n",
    "            )\n",
    "            \n",
    "            query_embeddings = query_encoder(query_tokens)\n",
    "            query_embeddings = torch.nn.functional.normalize(query_embeddings, p=2, dim=1)\n",
    "            \n",
    "            # Move query embeddings to CPU for comparison with all products\n",
    "            query_embeddings_cpu = query_embeddings.cpu()\n",
    "            \n",
    "            # Compute similarities with all products\n",
    "            similarities = query_embeddings_cpu @ all_product_embeddings.T\n",
    "            \n",
    "            # Get top-k indices\n",
    "            _, top_indices = torch.topk(similarities, k=k, dim=1)\n",
    "            \n",
    "            # Convert to list for evaluation\n",
    "            for i, (query_id, true_product_id) in enumerate(zip(range(len(queries)), product_ids)):\n",
    "                total_queries += 1\n",
    "                top_k_product_ids = [all_product_ids[idx] for idx in top_indices[i].tolist()]\n",
    "                \n",
    "                # Check if true product is in top-k\n",
    "                if true_product_id in top_k_product_ids:\n",
    "                    hits_at_k += 1\n",
    "                    # Calculate reciprocal rank\n",
    "                    rank = top_k_product_ids.index(true_product_id) + 1\n",
    "                    mrr += 1.0 / rank\n",
    "    \n",
    "    # Calculate metrics\n",
    "    hits_at_k_rate = hits_at_k / total_queries if total_queries > 0 else 0\n",
    "    mrr = mrr / total_queries if total_queries > 0 else 0\n",
    "    \n",
    "    print(f\"Evaluation Metrics:\")\n",
    "    print(f\"Hits@{k}: {hits_at_k_rate:.4f}\")\n",
    "    print(f\"MRR: {mrr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c81fb641-60e6-4a37-9bfb-958947bf851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_batch_negative_sampling_loss(query_embeddings, product_embeddings, negative_embeddings, temperature=0.1):\n",
    "    \"\"\"\n",
    "    Compute in-batch negative sampling loss (InfoNCE loss) with hard negatives.\n",
    "\n",
    "    Args:\n",
    "        query_embeddings: Query embeddings [batch_size, embed_dim]\n",
    "        product_embeddings: Product embeddings [batch_size, embed_dim]\n",
    "        negative_embeddings: Hard negative product embeddings [batch_size, embed_dim]\n",
    "        temperature: Temperature parameter for softmax.\n",
    "\n",
    "    Returns:\n",
    "        loss: InfoNCE loss\n",
    "    \"\"\"\n",
    "    batch_size = query_embeddings.shape[0]\n",
    "\n",
    "    # Squeeze negative embeddings to remove the unnecessary dimension\n",
    "    negative_embeddings = negative_embeddings.squeeze(1)  # Shape: [batch_size, embed_dim]\n",
    "\n",
    "    # Compute similarity scores\n",
    "    positive_sim = (query_embeddings * product_embeddings).sum(dim=1) / temperature\n",
    "    negative_sim = (query_embeddings @ negative_embeddings.T) / temperature  # Hard negatives\n",
    "\n",
    "    # Stack positives and negatives\n",
    "    logits = torch.cat([positive_sim.unsqueeze(1), negative_sim], dim=1)\n",
    "\n",
    "    # Labels: First column (positive pair) is correct\n",
    "    labels = torch.zeros(batch_size, dtype=torch.long, device=query_embeddings.device)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = torch.nn.functional.cross_entropy(logits, labels)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fca84a20-121a-48b7-9fe1-8cb70aae6494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_embedding_model(dataset, num_epochs=10, learning_rate=1e-4, eval_dataset=None):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    dataset = ProductSearchDataset(dataset)\n",
    "    eval_dataset = ProductSearchDataset(eval_dataset)\n",
    "\n",
    "    embed_size = 512\n",
    "    output_embed_size = 128\n",
    "    query_max_len = 32\n",
    "    product_max_len = 512\n",
    "    batch_size = 8\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    # Initialize encoders\n",
    "    query_encoder = QueryEncoder(vocab_size=tokenizer.vocab_size, embed_dim=embed_size, output_embed_dim=output_embed_size).to(device)\n",
    "    product_encoder = ProductEncoder(vocab_size=tokenizer.vocab_size, embed_dim=embed_size, output_embed_dim=output_embed_size).to(device)\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    optimizer = torch.optim.Adam(list(query_encoder.parameters()) + list(product_encoder.parameters()), lr=learning_rate)\n",
    "\n",
    "    scaler = torch.amp.GradScaler(device)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "\n",
    "    total_steps = len(dataloader) * num_epochs\n",
    "    main_progress_bar = tqdm(total=total_steps, desc=\"Training Progress\", position=0)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        query_encoder.train()\n",
    "        product_encoder.train()\n",
    "        epoch_loss = []\n",
    "\n",
    "        epoch_desc = f\"Epoch {epoch+1}/{num_epochs}\"\n",
    "        epoch_progress = tqdm(dataloader, desc=epoch_desc, leave=False, position=1)\n",
    "\n",
    "        for batch_idx, batch_data in enumerate(epoch_progress):\n",
    "            queries, product_descs, product_ids, cluster_ids = batch_data\n",
    "\n",
    "            query_tokens = tokenizer(queries, padding=True, truncation=True, return_tensors=\"pt\", max_length=query_max_len).to(device)\n",
    "            product_tokens = tokenizer(product_descs, padding=True, truncation=True, return_tensors=\"pt\", max_length=product_max_len).to(device)\n",
    "\n",
    "            with torch.amp.autocast(device.type):\n",
    "                query_embeddings = query_encoder(query_tokens)\n",
    "                product_embeddings = product_encoder(product_tokens)\n",
    "\n",
    "                query_embeddings = torch.nn.functional.normalize(query_embeddings, p=2, dim=1)\n",
    "                product_embeddings = torch.nn.functional.normalize(product_embeddings, p=2, dim=1)\n",
    "\n",
    "                # Get hard negatives from the batch\n",
    "                negative_embeddings = batch_hard_negative_sampling(product_ids, cluster_ids, product_embeddings)\n",
    "\n",
    "                loss = in_batch_negative_sampling_loss(query_embeddings, product_embeddings, negative_embeddings)\n",
    "\n",
    "            epoch_loss.append(loss.item())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            main_progress_bar.update(1)\n",
    "            epoch_progress.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "        avg_loss = np.mean(epoch_loss)\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        scheduler.step(avg_loss)\n",
    "\n",
    "        if eval_dataset is not None:\n",
    "            print(\"\\nEvaluating model...\")\n",
    "            evaluate_model(query_encoder, product_encoder, eval_dataset, tokenizer, query_max_len, product_max_len, device=device)\n",
    "\n",
    "    main_progress_bar.close()\n",
    "    return query_encoder, product_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07c44330-23a2-426c-942d-98224e8d4f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.QueryEncoder"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(query_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe31f5f5-24f8-44dd-ba20-60f011bf6814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6fc2f6dc4024dc98f8765783f01dd2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/420 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/15:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/15, Average Loss: 2.2159\n",
      "\n",
      "Evaluating model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86ab0e2d35ab409f93f5db3147581f7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding Products:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db46fb19e1e14180ac182c03dbf0611e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Queries:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Hits@10: 0.1562\n",
      "MRR: 0.0557\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/15:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/15, Average Loss: 2.2027\n",
      "\n",
      "Evaluating model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05fd837d25744c1196fbf6cbe6b06681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding Products:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9791f950a639439db7726ef2f8403b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Queries:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Hits@10: 0.1562\n",
      "MRR: 0.0455\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/15:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/15, Average Loss: 2.2121\n",
      "\n",
      "Evaluating model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "277e9e89e27e48beaa6c10395329c9a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding Products:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588a0571929948559d2bc172c9bcf86a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Queries:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Hits@10: 0.1719\n",
      "MRR: 0.0501\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/15:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/15, Average Loss: 2.1916\n",
      "\n",
      "Evaluating model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce8d9135d9b4bbbb2d16f27fd28443f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding Products:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "482e98f280d54762a3e3df0cdebbe2ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Queries:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Hits@10: 0.1562\n",
      "MRR: 0.0558\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/15:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/15, Average Loss: 2.2000\n",
      "\n",
      "Evaluating model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f4a0cf45d9d45fcafe5b8438340b443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding Products:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d71d99a92f96401a9c4a486ff2017d3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Queries:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Hits@10: 0.1719\n",
      "MRR: 0.0510\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/15:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/15, Average Loss: 2.2054\n",
      "\n",
      "Evaluating model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da06d1e084f44d598f748e2c616fe56a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding Products:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d119d582daaf4bb69040d1763e52630a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Queries:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Hits@10: 0.1875\n",
      "MRR: 0.0687\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/15:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/15, Average Loss: 2.2102\n",
      "\n",
      "Evaluating model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ed0a7cb24c04712aff3e7e06c0674af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding Products:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be27405c57ce41c18987eccf4f4af127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Queries:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Hits@10: 0.2656\n",
      "MRR: 0.0872\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/15:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/15, Average Loss: 2.1887\n",
      "\n",
      "Evaluating model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0042c6df10a84c5989bf6efd6dca3518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding Products:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e48ec72577f94daeb0d7cf10ed47c44b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Queries:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Hits@10: 0.3281\n",
      "MRR: 0.1150\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/15:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/15, Average Loss: 2.1301\n",
      "\n",
      "Evaluating model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30e07288a0d64e27972b2c72241fd5ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding Products:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52f8262219e458daebc98635e82a943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Queries:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Hits@10: 0.2344\n",
      "MRR: 0.0855\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/15:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/15, Average Loss: 2.0246\n",
      "\n",
      "Evaluating model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "529f6c53ec4a471b9a1f9416e18c6b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding Products:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5924387d91c547f9889bcb3357109c59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Queries:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Hits@10: 0.2812\n",
      "MRR: 0.0866\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/15:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11/15, Average Loss: 1.9496\n",
      "\n",
      "Evaluating model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a41fc7c2aafe4300a9d942eb2715eb08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding Products:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f150eb58cb4124803b844d86907bc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Queries:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Hits@10: 0.3438\n",
      "MRR: 0.1108\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/15:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12/15, Average Loss: 1.8767\n",
      "\n",
      "Evaluating model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20309dda6fcc4facad5b010aacfce539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding Products:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edecb46a3a604a0eb299b81a05a19b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Queries:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Hits@10: 0.2969\n",
      "MRR: 0.0879\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/15:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13/15, Average Loss: 1.8032\n",
      "\n",
      "Evaluating model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e1c8ec2142f4a4d86f992ad38102ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding Products:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca3735e66c84a619c76c1883ad4e911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Queries:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Hits@10: 0.3594\n",
      "MRR: 0.1181\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/15:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14/15, Average Loss: 1.7460\n",
      "\n",
      "Evaluating model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23148f1f254b4c75b2b77debcbf47f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding Products:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "124f19012efb47c59c340df9cda8ac4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Queries:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Hits@10: 0.3750\n",
      "MRR: 0.1227\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/15:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15/15, Average Loss: 1.7822\n",
      "\n",
      "Evaluating model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91530d3ea82745ff9a3c4d37f75dbb43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding Products:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "668471b3837649bab85b656aee211a5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Queries:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Hits@10: 0.3281\n",
      "MRR: 0.1497\n"
     ]
    }
   ],
   "source": [
    "query_encoder, product_encoder = train_embedding_model(train_dataset, num_epochs=15, eval_dataset=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04553728-b6c6-45ab-8e2b-a5062a03d82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models\n",
    "torch.save(query_encoder.state_dict(), 'data/home_products_query_encoder.pt')\n",
    "torch.save(product_encoder.state_dict(), 'data/home_products_description_encoder.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bf1b22-29cc-4786-9fbe-f7477c6aed75",
   "metadata": {},
   "source": [
    "## Search for products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e6ade2-4844-486b-8914-a5e42de8c329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import sqlite3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
