{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # used for PyTorch datasets and deep learning\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer # used for NLP tokenizartion\n",
    "from tqdm.auto import tqdm # progress bar for loops\n",
    "from sklearn.model_selection import train_test_split # splits data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductSearchDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.data = dataset # takes in a dataset\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0] # return total # of rows (products) in the dataset\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index] # retrieve a row based on index\n",
    "\n",
    "        # extract data\n",
    "        product_id = row['id']\n",
    "        product_desc = row['description']\n",
    "        product_cluster = row['label']\n",
    "        \n",
    "        # get all queries\n",
    "        product_queries = row[['query_1', 'query_2', 'query_3', 'query_4', 'query_5']].values\n",
    "    \n",
    "        # randomly select one query for training\n",
    "        query = np.random.choice(product_queries)\n",
    "    \n",
    "        return query, product_desc, product_id, product_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cd_vinyl_products_with_sample_queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>label</th>\n",
       "      <th>query_1</th>\n",
       "      <th>query_2</th>\n",
       "      <th>query_3</th>\n",
       "      <th>query_4</th>\n",
       "      <th>query_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00BV9RZSO</td>\n",
       "      <td>Elephant</td>\n",
       "      <td>doulbe 180gm vinyl lp pressing of this 2003 al...</td>\n",
       "      <td>67</td>\n",
       "      <td>\"white stripes vinyl LP 2003\"</td>\n",
       "      <td>\"garage rock revival music\"</td>\n",
       "      <td>\"analog recording equipment bands\"</td>\n",
       "      <td>\"Detroit indie music albums\"</td>\n",
       "      <td>\"raw simplicity music composition\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B0009ELZAG</td>\n",
       "      <td>The Beach Boys: Pet Sounds</td>\n",
       "      <td>the tracks are 1 wouldnt it be nice 2 you stil...</td>\n",
       "      <td>45</td>\n",
       "      <td>\"Pet Sounds bonus tracks vinyl\"</td>\n",
       "      <td>\"Beach Boys album 1966\"</td>\n",
       "      <td>\"Brian Wilson music compositions\"</td>\n",
       "      <td>\"California pop music LP\"</td>\n",
       "      <td>\"melodic pop rock records\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00M889IDM</td>\n",
       "      <td>Eric Clapton &amp; Friends: The Breeze</td>\n",
       "      <td>eric clapton has often stated that jj cale is ...</td>\n",
       "      <td>54</td>\n",
       "      <td>\"Eric Clapton tribute album JJ Cale\"</td>\n",
       "      <td>\"rock history appreciation music\"</td>\n",
       "      <td>\"famous musicians collaborations LP\"</td>\n",
       "      <td>\"JJ Cale covers by artists\"</td>\n",
       "      <td>\"1972 single call me the breeze\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00NQKWA6S</td>\n",
       "      <td>The Endless River</td>\n",
       "      <td>2014 release the 15th and final studio album f...</td>\n",
       "      <td>3</td>\n",
       "      <td>\"David Gilmour final studio album\"</td>\n",
       "      <td>\"British rock band unreleased tracks\"</td>\n",
       "      <td>\"Pink Floyd leftovers project\"</td>\n",
       "      <td>\"veteran rock musicians LP\"</td>\n",
       "      <td>\"coproduced by Phil Manzanera\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B08HGPZ1Q5</td>\n",
       "      <td>American Beauty</td>\n",
       "      <td>the crown jewel of the deads studio output fea...</td>\n",
       "      <td>63</td>\n",
       "      <td>\"Grateful Dead crown jewel LP\"</td>\n",
       "      <td>\"50th-anniversary remastered vinyl\"</td>\n",
       "      <td>\"psychedelic rock classics\"</td>\n",
       "      <td>\"180-gram vinyl reissue\"</td>\n",
       "      <td>\"tracklist box of rain\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                               title  \\\n",
       "0  B00BV9RZSO                            Elephant   \n",
       "1  B0009ELZAG          The Beach Boys: Pet Sounds   \n",
       "2  B00M889IDM  Eric Clapton & Friends: The Breeze   \n",
       "3  B00NQKWA6S                   The Endless River   \n",
       "4  B08HGPZ1Q5                     American Beauty   \n",
       "\n",
       "                                         description  label  \\\n",
       "0  doulbe 180gm vinyl lp pressing of this 2003 al...     67   \n",
       "1  the tracks are 1 wouldnt it be nice 2 you stil...     45   \n",
       "2  eric clapton has often stated that jj cale is ...     54   \n",
       "3  2014 release the 15th and final studio album f...      3   \n",
       "4  the crown jewel of the deads studio output fea...     63   \n",
       "\n",
       "                                 query_1  \\\n",
       "0          \"white stripes vinyl LP 2003\"   \n",
       "1        \"Pet Sounds bonus tracks vinyl\"   \n",
       "2   \"Eric Clapton tribute album JJ Cale\"   \n",
       "3     \"David Gilmour final studio album\"   \n",
       "4         \"Grateful Dead crown jewel LP\"   \n",
       "\n",
       "                                 query_2  \\\n",
       "0            \"garage rock revival music\"   \n",
       "1                \"Beach Boys album 1966\"   \n",
       "2      \"rock history appreciation music\"   \n",
       "3  \"British rock band unreleased tracks\"   \n",
       "4    \"50th-anniversary remastered vinyl\"   \n",
       "\n",
       "                                query_3                       query_4  \\\n",
       "0    \"analog recording equipment bands\"  \"Detroit indie music albums\"   \n",
       "1     \"Brian Wilson music compositions\"     \"California pop music LP\"   \n",
       "2  \"famous musicians collaborations LP\"   \"JJ Cale covers by artists\"   \n",
       "3        \"Pink Floyd leftovers project\"   \"veteran rock musicians LP\"   \n",
       "4           \"psychedelic rock classics\"      \"180-gram vinyl reissue\"   \n",
       "\n",
       "                               query_5  \n",
       "0  \"raw simplicity music composition\"   \n",
       "1          \"melodic pop rock records\"   \n",
       "2    \"1972 single call me the breeze\"   \n",
       "3      \"coproduced by Phil Manzanera\"   \n",
       "4             \"tracklist box of rain\"   "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = train_test_split(df, test_size=0.2, random_state=3478)\n",
    "train_dataset.reset_index(drop=True, inplace=True)\n",
    "val_dataset.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryEncoder(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, output_embed_dim):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = torch.nn.Embedding(vocab_size, embed_dim)\n",
    "        # use fewer transformer layers for queries since they're shorter\n",
    "        self.encoder = torch.nn.TransformerEncoder(\n",
    "            torch.nn.TransformerEncoderLayer(embed_dim, nhead=8, batch_first=True),\n",
    "            num_layers=2,\n",
    "            norm=torch.nn.LayerNorm([embed_dim]),\n",
    "            enable_nested_tensor=False\n",
    "        )\n",
    "        self.projection = torch.nn.Linear(embed_dim, output_embed_dim)\n",
    "        \n",
    "    def forward(self, tokenizer_output):\n",
    "        # move inputs to the same device as the model\n",
    "        input_ids = tokenizer_output['input_ids'].to(self.embedding_layer.weight.device)\n",
    "        attention_mask = tokenizer_output['attention_mask'].to(self.embedding_layer.weight.device)\n",
    "        \n",
    "        x = self.embedding_layer(input_ids)\n",
    "        x = self.encoder(x, src_key_padding_mask=attention_mask.logical_not())\n",
    "        # use mean pooling instead of CLS token for queries\n",
    "        # this helps capture information from all tokens in short queries\n",
    "        mask_expanded = attention_mask.unsqueeze(-1).expand(x.size())\n",
    "        sum_embeddings = torch.sum(x * mask_expanded, 1)\n",
    "        sum_mask = torch.sum(mask_expanded, 1)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return self.projection(mean_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductEncoder(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, output_embed_dim):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = torch.nn.Embedding(vocab_size, embed_dim)\n",
    "        # use more transformer layers for product descriptions since they're longer\n",
    "        self.encoder = torch.nn.TransformerEncoder(\n",
    "            torch.nn.TransformerEncoderLayer(embed_dim, nhead=8, batch_first=True),\n",
    "            num_layers=4,\n",
    "            norm=torch.nn.LayerNorm([embed_dim]),\n",
    "            enable_nested_tensor=False\n",
    "        )\n",
    "        self.projection = torch.nn.Linear(embed_dim, output_embed_dim)\n",
    "        \n",
    "    def forward(self, tokenizer_output):\n",
    "        # move inputs to the same device as the model\n",
    "        input_ids = tokenizer_output['input_ids'].to(self.embedding_layer.weight.device)\n",
    "        attention_mask = tokenizer_output['attention_mask'].to(self.embedding_layer.weight.device)\n",
    "        \n",
    "        x = self.embedding_layer(input_ids)\n",
    "        x = self.encoder(x, src_key_padding_mask=attention_mask.logical_not())\n",
    "        # use CLS token for product descriptions\n",
    "        cls_embed = x[:,0,:]\n",
    "        return self.projection(cls_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_hard_negative_sampling(product_ids, cluster_ids, product_embeddings, num_negatives=1):\n",
    "    \"\"\"\n",
    "    Sample hard negatives from the current batch, ensuring negatives come from different clusters.\n",
    "\n",
    "    Args:\n",
    "        product_ids (list): List of product IDs in the batch.\n",
    "        cluster_ids (list): List of corresponding cluster IDs in the batch.\n",
    "        product_embeddings (torch.Tensor): Tensor of product embeddings in the batch [batch_size, embed_dim].\n",
    "        num_negatives (int): Number of negatives per query.\n",
    "\n",
    "    Returns:\n",
    "        neg_embeddings (torch.Tensor): Tensor of hard negative product embeddings [batch_size, num_negatives, embed_dim].\n",
    "    \"\"\"\n",
    "    batch_size = len(product_ids)\n",
    "    neg_samples = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        # get current cluster ID\n",
    "        current_cluster = cluster_ids[i]\n",
    "\n",
    "        # find indices of products in the batch from a different cluster\n",
    "        negative_indices = [j for j in range(batch_size) if cluster_ids[j] != current_cluster]\n",
    "\n",
    "        # sample negatives\n",
    "        sampled_negatives = random.sample(negative_indices, num_negatives)\n",
    "        \n",
    "        # store their embeddings\n",
    "        neg_samples.append(product_embeddings[sampled_negatives])\n",
    "\n",
    "    # stack negatives into a tensor [batch_size, num_negatives, embed_dim]\n",
    "    neg_embeddings = torch.stack(neg_samples).to(product_embeddings.device)\n",
    "    \n",
    "    return neg_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(query_encoder, product_encoder, eval_dataset, tokenizer, query_max_len, product_max_len, k=10, device='cuda'):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the evaluation dataset\n",
    "    \n",
    "    Args:\n",
    "        query_encoder: Query encoder model\n",
    "        product_encoder: Product encoder model\n",
    "        eval_dataset: Evaluation dataset\n",
    "        tokenizer: Tokenizer\n",
    "        query_max_len: Maximum query length\n",
    "        product_max_len: Maximum product description length\n",
    "        k: Number of top results to consider for metrics\n",
    "        device: Device to use for computations\n",
    "    \"\"\"\n",
    "    query_encoder.eval()\n",
    "    product_encoder.eval()\n",
    "    \n",
    "    # create evaluation dataloader\n",
    "    eval_dataloader = torch.utils.data.DataLoader(eval_dataset, batch_size=8, shuffle=False)\n",
    "    \n",
    "    # first pass: encode all products\n",
    "    all_product_ids = []\n",
    "    all_product_embeddings = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_data in tqdm(eval_dataloader, desc=\"Encoding Products\"):\n",
    "            _, product_descs, product_ids, _ = batch_data\n",
    "            \n",
    "            product_tokens = tokenizer(\n",
    "                product_descs, \n",
    "                padding=True, \n",
    "                truncation=True, \n",
    "                return_tensors=\"pt\", \n",
    "                max_length=product_max_len\n",
    "            )\n",
    "            \n",
    "            product_embeddings = product_encoder(product_tokens)\n",
    "            product_embeddings = torch.nn.functional.normalize(product_embeddings, p=2, dim=1)\n",
    "            \n",
    "            all_product_ids.extend(product_ids)\n",
    "            all_product_embeddings.append(product_embeddings.cpu())  # move to CPU to save GPU memory\n",
    "    \n",
    "    # concatenate all product embeddings\n",
    "    all_product_embeddings = torch.cat(all_product_embeddings, dim=0)\n",
    "    \n",
    "    # second pass: evaluate queries\n",
    "    total_queries = 0\n",
    "    hits_at_k = 0\n",
    "    mrr = 0.0  # mean Reciprocal Rank\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_data in tqdm(eval_dataloader, desc=\"Evaluating Queries\"):\n",
    "            queries, _, product_ids, _ = batch_data\n",
    "            \n",
    "            query_tokens = tokenizer(\n",
    "                queries, \n",
    "                padding=True, \n",
    "                truncation=True, \n",
    "                return_tensors=\"pt\", \n",
    "                max_length=query_max_len\n",
    "            )\n",
    "            \n",
    "            query_embeddings = query_encoder(query_tokens)\n",
    "            query_embeddings = torch.nn.functional.normalize(query_embeddings, p=2, dim=1)\n",
    "            \n",
    "            # move query embeddings to CPU for comparison with all products\n",
    "            query_embeddings_cpu = query_embeddings.cpu()\n",
    "            \n",
    "            # compute similarities with all products\n",
    "            similarities = query_embeddings_cpu @ all_product_embeddings.T\n",
    "            \n",
    "            # get top-k indices\n",
    "            _, top_indices = torch.topk(similarities, k=k, dim=1)\n",
    "            \n",
    "            # convert to list for evaluation\n",
    "            for i, (query_id, true_product_id) in enumerate(zip(range(len(queries)), product_ids)):\n",
    "                total_queries += 1\n",
    "                top_k_product_ids = [all_product_ids[idx] for idx in top_indices[i].tolist()]\n",
    "                \n",
    "                # check if true product is in top-k\n",
    "                if true_product_id in top_k_product_ids:\n",
    "                    hits_at_k += 1\n",
    "                    # calculate reciprocal rank\n",
    "                    rank = top_k_product_ids.index(true_product_id) + 1\n",
    "                    mrr += 1.0 / rank\n",
    "    \n",
    "    # calculate metrics\n",
    "    hits_at_k_rate = hits_at_k / total_queries if total_queries > 0 else 0\n",
    "    mrr = mrr / total_queries if total_queries > 0 else 0\n",
    "    \n",
    "    print(f\"Evaluation Metrics:\")\n",
    "    print(f\"Hits@{k}: {hits_at_k_rate:.4f}\")\n",
    "    print(f\"MRR: {mrr:.4f}\")\n",
    "\n",
    "    return hits_at_k_rate, mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_batch_negative_sampling_loss(query_embeddings, product_embeddings, negative_embeddings, temperature=0.1):\n",
    "    \"\"\"\n",
    "    Compute in-batch negative sampling loss (InfoNCE loss) with hard negatives.\n",
    "\n",
    "    Args:\n",
    "        query_embeddings: Query embeddings [batch_size, embed_dim]\n",
    "        product_embeddings: Product embeddings [batch_size, embed_dim]\n",
    "        negative_embeddings: Hard negative product embeddings [batch_size, embed_dim]\n",
    "        temperature: Temperature parameter for softmax.\n",
    "\n",
    "    Returns:\n",
    "        loss: InfoNCE loss\n",
    "    \"\"\"\n",
    "    batch_size = query_embeddings.shape[0]\n",
    "\n",
    "    # squeeze negative embeddings to remove the unnecessary dimension\n",
    "    negative_embeddings = negative_embeddings.squeeze(1)\n",
    "\n",
    "    # compute similarity scores\n",
    "    positive_sim = (query_embeddings * product_embeddings).sum(dim=1) / temperature\n",
    "    negative_sim = (query_embeddings @ negative_embeddings.T) / temperature  # Hard negatives\n",
    "\n",
    "    # stack positives and negatives\n",
    "    logits = torch.cat([positive_sim.unsqueeze(1), negative_sim], dim=1)\n",
    "\n",
    "    # labels: First column (positive pair) is correct\n",
    "    labels = torch.zeros(batch_size, dtype=torch.long, device=query_embeddings.device)\n",
    "\n",
    "    # compute loss\n",
    "    loss = torch.nn.functional.cross_entropy(logits, labels)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_embedding_model(dataset, num_epochs=10, learning_rate=1e-4, eval_dataset=None, patience=10):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    dataset = ProductSearchDataset(dataset)\n",
    "    eval_dataset = ProductSearchDataset(eval_dataset)\n",
    "\n",
    "    embed_size = 512\n",
    "    output_embed_size = 128\n",
    "    query_max_len = 32\n",
    "    product_max_len = 512\n",
    "    batch_size = 8\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    # initialize encoders\n",
    "    query_encoder = QueryEncoder(vocab_size=tokenizer.vocab_size, embed_dim=embed_size, output_embed_dim=output_embed_size).to(device)\n",
    "    product_encoder = ProductEncoder(vocab_size=tokenizer.vocab_size, embed_dim=embed_size, output_embed_dim=output_embed_size).to(device)\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    optimizer = torch.optim.Adam(list(query_encoder.parameters()) + list(product_encoder.parameters()), lr=learning_rate)\n",
    "\n",
    "    scaler = torch.amp.GradScaler(device)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "\n",
    "    total_steps = len(dataloader) * num_epochs\n",
    "    main_progress_bar = tqdm(total=total_steps, desc=\"Training Progress\", position=0)\n",
    "\n",
    "    best_hits = 0\n",
    "    patience_counter = 0\n",
    "    best_query_encoder_weights = None\n",
    "    best_product_encoder_weights = None\n",
    "\n",
    "    \n",
    "    hits_log = []\n",
    "    mrr_log = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # early stopping check\n",
    "        if patience_counter == patience:\n",
    "            break\n",
    "        \n",
    "        query_encoder.train()\n",
    "        product_encoder.train()\n",
    "        epoch_loss = []\n",
    "\n",
    "        epoch_desc = f\"Epoch {epoch+1}/{num_epochs}\"\n",
    "        epoch_progress = tqdm(dataloader, desc=epoch_desc, leave=False, position=1)\n",
    "\n",
    "        for batch_idx, batch_data in enumerate(epoch_progress):\n",
    "            queries, product_descs, product_ids, cluster_ids = batch_data\n",
    "\n",
    "            query_tokens = tokenizer(queries, padding=True, truncation=True, return_tensors=\"pt\", max_length=query_max_len).to(device)\n",
    "            product_tokens = tokenizer(product_descs, padding=True, truncation=True, return_tensors=\"pt\", max_length=product_max_len).to(device)\n",
    "\n",
    "            with torch.amp.autocast(device.type):\n",
    "                query_embeddings = query_encoder(query_tokens)\n",
    "                product_embeddings = product_encoder(product_tokens)\n",
    "\n",
    "                query_embeddings = torch.nn.functional.normalize(query_embeddings, p=2, dim=1)\n",
    "                product_embeddings = torch.nn.functional.normalize(product_embeddings, p=2, dim=1)\n",
    "\n",
    "                # get hard negatives from the batch\n",
    "                negative_embeddings = batch_hard_negative_sampling(product_ids, cluster_ids, product_embeddings, num_negatives=1)\n",
    "\n",
    "                loss = in_batch_negative_sampling_loss(query_embeddings, product_embeddings, negative_embeddings)\n",
    "\n",
    "            epoch_loss.append(loss.item())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            main_progress_bar.update(1)\n",
    "            epoch_progress.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "        avg_loss = np.mean(epoch_loss)\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        scheduler.step(avg_loss)\n",
    "\n",
    "        if eval_dataset is not None:\n",
    "            print(\"\\nEvaluating model...\")\n",
    "            hits_in_top_k, mrr = evaluate_model(query_encoder, product_encoder, eval_dataset, tokenizer, query_max_len, product_max_len, device=device)\n",
    "            if hits_in_top_k > best_hits:\n",
    "                best_hits = hits_in_top_k\n",
    "                best_query_encoder_weights = query_encoder.state_dict()\n",
    "                best_product_encoder_weights = product_encoder.state_dict()\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            hits_log.append(hits_in_top_k)\n",
    "            mrr_log.append(mrr)\n",
    "\n",
    "    main_progress_bar.close()\n",
    "\n",
    "    # load the model weights with the best validation hits\n",
    "    query_encoder.load_state_dict(best_query_encoder_weights)\n",
    "    product_encoder.load_state_dict(best_product_encoder_weights)\n",
    "\n",
    "    return query_encoder, product_encoder, hits_log, mrr_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 28/2800 [14:01<15:58:04, 20.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100, Average Loss: 2.2083\n",
      "\n",
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Products: 100%|██████████| 7/7 [00:01<00:00,  4.03it/s]\n",
      "Evaluating Queries: 100%|██████████| 7/7 [00:00<00:00, 138.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Hits@10: 0.1786\n",
      "MRR: 0.0538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|▏         | 56/2800 [29:27<29:34:59, 38.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/100, Average Loss: 2.1882\n",
      "\n",
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Products: 100%|██████████| 7/7 [00:02<00:00,  3.16it/s]\n",
      "Evaluating Queries: 100%|██████████| 7/7 [00:00<00:00, 115.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Hits@10: 0.1786\n",
      "MRR: 0.0530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   3%|▎         | 84/2800 [51:07<27:50:09, 36.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/100, Average Loss: 2.1779\n",
      "\n",
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Products: 100%|██████████| 7/7 [00:02<00:00,  2.68it/s]\n",
      "Evaluating Queries: 100%|██████████| 7/7 [00:00<00:00, 83.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Hits@10: 0.1607\n",
      "MRR: 0.0496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   4%|▍         | 106/2800 [1:04:03<18:55:39, 25.29s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m query_encoder, product_encoder, hits_in_top_k_history, mrr_history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_embedding_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 71\u001b[0m, in \u001b[0;36mtrain_embedding_model\u001b[0;34m(dataset, num_epochs, learning_rate, eval_dataset, patience)\u001b[0m\n\u001b[1;32m     68\u001b[0m epoch_loss\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     70\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 71\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n\u001b[1;32m     73\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "query_encoder, product_encoder, hits_in_top_k_history, mrr_history = train_embedding_model(train_dataset, num_epochs=100, eval_dataset=val_dataset, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
